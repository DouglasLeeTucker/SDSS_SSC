{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **20 Apr 2020: Use this to clean new SSC, then match with the old SSC**\n",
    "\n",
    "### **THIS IS A CLEANED UP VERSION, REMOVING SEVERAL REDUNDANT PARTS**\n",
    "\n",
    "This matches only the high nEpoch stars in the new cat with the old SSC.\n",
    "\n",
    "Notes reg steps done:\n",
    "1. ID nEpoch > threshold objects in the new SSC\n",
    "2. Clean up the new cat, use only good g, r and i mags/ err obj\n",
    "3. Match to old SSC (try pyspherematch and Dask.delayed)\n",
    "4. Write out matched objects to csv files\n",
    "\n",
    "**NO COMPARISONS DONE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.table import hstack\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "import dask\n",
    "from dask import compute, delayed\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "# Scipy\n",
    "from scipy.spatial import cKDTree as KDT\n",
    "\n",
    "# astroML\n",
    "from astroML.plotting import hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspherematch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DEFINE INPUT FILENAMES AND PROG CONSTANTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEPOCH THRESHOLD FOR CLEANING NEW SSC\n",
    "IZ_low_epoch = 5\n",
    "\n",
    "# MATCH RAD FOR PYSPHEREMATCH\n",
    "tol_asec = 2. # matching radius in arc.sec\n",
    "tol_deg = tol_asec/3600.\n",
    "\n",
    "# MAX PERMITTED MAG ERROR\n",
    "max_MAGerr = 0.05\n",
    "\n",
    "# The new SSC\n",
    "nSSC = 'NEW_stripe82calibStars_v0.dat'\n",
    "\n",
    "# The new PREMATCH SSC\n",
    "nSSC_prematch = 'NEW_stripe82calibStars_prematch.csv'\n",
    "\n",
    "# The new MATCHED SSC\n",
    "nSSC_matched = 'NEW_stripe82calibStars_matched.csv'\n",
    "\n",
    "# The old SSC\n",
    "oSSC = 'stripe82calibStars_v2.6.dat'\n",
    "\n",
    "# The old MATCHED SSC\n",
    "oSSC_matched = 'stripe82calibStars_matched.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIST OF NAMES OF DF AND THEIR CUTS**\n",
    "\n",
    "    new_df = as read in KT 2020 cat\n",
    "    new_df1 = after removing null and low nepoch obj\n",
    "    new_df2 = select good r-mag and r-err\n",
    "    new_df3 = select good g-mag and g-err\n",
    "    new_df4 = select good i-mag and i-err\n",
    "    \n",
    "    old_df = as read in ZI 2007 cat\n",
    "    \n",
    "    new_prematch_df = prior to matching cleaned 2020\n",
    "    old_prematch_df = prior to matching as read 2007\n",
    "    \n",
    "    new_matched_df = matched new df\n",
    "    old_matched_df = matched old df\n",
    "    \n",
    "    The following df are written out to csv files\n",
    "    new_prematch_df\n",
    "    new_matched_df\n",
    "    old_matched_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OPEN A LOG FILE**\n",
    "\n",
    "## **BEFORE QUITTING**\n",
    "## **REMEMBER TO RUN THE LAST CELL TO CLOSE THE LOG FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fil = 'Match_NvsO_SSCv2.log'\n",
    "outlog = open(log_fil,'w')\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "outlog.write(\"Running Match_NvsO_SSCv1 on %s\\n\" % (today));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **READ IN THE NEW SSC INTO DASK DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df, as read: num rows, cols:  1007137 37\n",
      "CPU times: user 14.1 s, sys: 3.61 s, total: 17.7 s\n",
      "Wall time: 7.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Ncolnames = ['Ncalib_fla', 'Nra', 'Ndec', 'NraRMS', 'NdecRMS', 'NnEpochs', 'NAR_val', \n",
    "                'Nu_Nobs', 'Nu_mMed', 'Nu_mMean', 'Nu_mErr', 'Nu_rms_scatt', 'Nu_chi2',\n",
    "                'Ng_Nobs', 'Ng_mMed', 'Ng_mMean', 'Ng_mErr', 'Ng_rms_scatt', 'Ng_chi2',\n",
    "                'Nr_Nobs', 'Nr_mMed', 'Nr_mMean', 'Nr_mErr', 'Nr_rms_scatt', 'Nr_chi2',\n",
    "                'Ni_Nobs', 'Ni_mMed', 'Ni_mMean', 'Ni_mErr', 'Ni_rms_scatt', 'Ni_chi2',\n",
    "                'Nz_Nobs', 'Nz_mMed', 'Nz_mMean', 'Nz_mErr', 'Nz_rms_scatt', 'Nz_chi2']\n",
    "\n",
    "# USING DASK DATAFRAME\n",
    "df_nSSC = dd.read_csv(nSSC,delimiter=\",\",header=None,names=Ncolnames,\n",
    "                      assume_missing=True,low_memory=False,comment='#')\n",
    "new_df = df_nSSC.compute()\n",
    "new_df.head()\n",
    "nrows,ncols = new_df.shape\n",
    "print('New df, as read: num rows, cols: ',nrows,ncols)\n",
    "outlog.write('New df, as read: num rows %d, cols %d\\n' % (nrows,ncols));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DROP ROWS WITH NAN AND NULL OBJ IN THE NEW SSC**\n",
    "\n",
    "USE DASK DATAFRAME, DROPNA()\n",
    "\n",
    "new_df = new_df.dropna() \n",
    "print('Num obj in new ssc: ',len(new_df['ra']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df, no NULLS: num rows, cols:  1006849 37\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.dropna() \n",
    "nrows,ncols = new_df.shape\n",
    "print('New df, no NULLS: num rows, cols: ',nrows,ncols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Dropping all nulls and nans\\n')\n",
    "outlog.write('New df, no NULLS: num rows %d, cols %d \\n' % (nrows,ncols));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIND ALL THE LO AND HI NOBS OBJECTS IN THE NEW SSC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nepoch threshold used:  5\n",
      "Num no nepoch obj:  1666\n",
      "Num lo nepoch obj:  1413\n",
      "Num hi nepoch obj:  1003770\n",
      "CPU times: user 829 ms, sys: 11 ms, total: 840 ms\n",
      "Wall time: 837 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# new ssc\n",
    "new_nepochs = new_df['NnEpochs'].astype(int) \n",
    "\n",
    "no_nepochs = list(filter(lambda x: x == 0, new_nepochs)) # 0 obs = no matches\n",
    "lo_nepochs = list(filter(lambda x: ((x > 0) and (x < IZ_low_epoch)), new_nepochs)) # 1 <= x < 5, will have matches\n",
    "hi_nepochs = list(filter(lambda x: x >= IZ_low_epoch, new_nepochs)) # > 5, will have close matches\n",
    "print('Nepoch threshold used: ', IZ_low_epoch)\n",
    "\n",
    "print('Num no nepoch obj: ',len(no_nepochs))\n",
    "print('Num lo nepoch obj: ',len(lo_nepochs))\n",
    "print('Num hi nepoch obj: ',len(hi_nepochs))\n",
    "\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Finding low nepoch objects\\n')\n",
    "outlog.write('Num no nepoch obj: %d\\n' % len(no_nepochs))\n",
    "outlog.write('Num lo nepoch obj: %d\\n' % len(lo_nepochs))\n",
    "outlog.write('Num hi nepoch obj: %d\\n' % len(hi_nepochs));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SELECT SUBSET OF NEW SSC WITH NEPOCHS >= THRESHOLD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New df, nEpochs > threshold: num rows, cols:  1003770 37\n",
      "CPU times: user 355 ms, sys: 261 ms, total: 617 ms\n",
      "Wall time: 605 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "new_df1 = new_df[new_df['NnEpochs'].astype(int) >= IZ_low_epoch]\n",
    "\n",
    "nrows1,ncols1 = new_df1.shape\n",
    "print('New df, nEpochs > threshold: num rows, cols: ',nrows1,ncols1)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, nEpochs > threshold: num rows %d, cols %d\\n' % (nrows1,ncols1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SELECT GOOD R-MAG AND R-MAG ERR OBJECTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1002128, 37)\n",
      "New df, RMAG > 0: num rows, cols:  1002128 37\n",
      "(995378, 37)\n",
      "New df, RERR < MAX ERR: num rows, cols:  995378 37\n"
     ]
    }
   ],
   "source": [
    "# get a df of obj with good phot\n",
    "# r_mag > 0 \n",
    "new_df2 = new_df1[(new_df1['Nr_mMed'] > 0)]\n",
    "print(new_df2.shape)\n",
    "\n",
    "nrows2,ncols2 = new_df2.shape\n",
    "print('New df, RMAG > 0: num rows, cols: ',nrows2,ncols2)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, RMAG > 0: num rows %d, cols %d\\n' % (nrows2,ncols2));\n",
    "\n",
    "# r_err\n",
    "new_df2 = new_df2[(new_df2['Nr_mErr'] <= max_MAGerr)]\n",
    "print(new_df2.shape)\n",
    "\n",
    "nrows2,ncols2 = new_df2.shape\n",
    "print('New df, RERR < MAX ERR: num rows, cols: ',nrows2,ncols2)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, RERR < MAX ERR: num rows %d, cols %d\\n' % (nrows2,ncols2));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SELECT GOOD G- AND I-MAG OBJECTS\n",
    "\n",
    "**These are the three mags used in the comparison with Gaia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **g-mag and g-err**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995187, 37)\n",
      "New df, GMAG > 0: num rows, cols:  995187 37\n",
      "(930765, 37)\n",
      "New df, GERR < MAX ERR: num rows, cols:  930765 37\n"
     ]
    }
   ],
   "source": [
    "# get a df of obj with good phot\n",
    "# g_mag > 0 \n",
    "new_df3 = new_df2[(new_df2['Ng_mMed'] > 0)]\n",
    "print(new_df3.shape)\n",
    "\n",
    "nrows3,ncols3 = new_df3.shape\n",
    "print('New df, GMAG > 0: num rows, cols: ',nrows3,ncols3)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, GMAG > 0: num rows %d, cols %d\\n' % (nrows3,ncols3));\n",
    "\n",
    "# g_err\n",
    "new_df3 = new_df3[(new_df3['Ng_mErr'] <= max_MAGerr)]\n",
    "print(new_df3.shape)\n",
    "\n",
    "nrows3,ncols3 = new_df3.shape\n",
    "print('New df, GERR < MAX ERR: num rows, cols: ',nrows3,ncols3)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, GERR < MAX ERR: num rows %d, cols %d\\n' % (nrows3,ncols3));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **i-mag and i-err**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(930637, 37)\n",
      "New df, IMAG > 0: num rows, cols:  930637 37\n",
      "(929407, 37)\n",
      "New df, IERR < MAX ERR: num rows, cols:  929407 37\n"
     ]
    }
   ],
   "source": [
    "# get a df of obj with good phot\n",
    "# i_mag > 0 \n",
    "new_df4 = new_df3[(new_df3['Ni_mMed'] > 0)]\n",
    "print(new_df4.shape)\n",
    "\n",
    "nrows4,ncols4 = new_df4.shape\n",
    "print('New df, IMAG > 0: num rows, cols: ',nrows4,ncols4)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, IMAG > 0: num rows %d, cols %d\\n' % (nrows4,ncols4));\n",
    "\n",
    "# i_err\n",
    "new_df4 = new_df4[(new_df4['Ni_mErr'] <= max_MAGerr)]\n",
    "print(new_df4.shape)\n",
    "\n",
    "nrows4,ncols4 = new_df4.shape\n",
    "print('New df, IERR < MAX ERR: num rows, cols: ',nrows4,ncols4)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, IERR < MAX ERR: num rows %d, cols %d\\n' % (nrows4,ncols4));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **READ IN THE OLD SSC INTO DASK DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old df, as read: num rows, cols:  1006849 37\n",
      "CPU times: user 11.6 s, sys: 2.45 s, total: 14 s\n",
      "Wall time: 4.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 37 Columns\n",
    "# Col 1 = junk str; Col 2-5 RA/Dec and errs; Col 6 nEpochs; Col 7 Ar_val\n",
    "# nobs, mMed, mMean, mErr, mRMS, mChi2 for \n",
    "# Col 8 - 13 = u, Col 14 - 19 = g, Col 20 - 25 = r, Col 26 - 31 = i, Col 32 - 37 = z\n",
    "Ocolnames = ['Ocalib_fla', 'Ora', 'Odec', 'OraRMS', 'OdecRMS', 'OnEpochs', 'OAR_val', \n",
    "                'Ou_Nobs', 'Ou_mMed', 'Ou_mMean', 'Ou_mErr', 'Ou_rms_scatt', 'Ou_chi2',\n",
    "                'Og_Nobs', 'Og_mMed', 'Og_mMean', 'Og_mErr', 'Og_rms_scatt', 'Og_chi2',\n",
    "                'Or_Nobs', 'Or_mMed', 'Or_mMean', 'Or_mErr', 'Or_rms_scatt', 'Or_chi2',\n",
    "                'Oi_Nobs', 'Oi_mMed', 'Oi_mMean', 'Oi_mErr', 'Oi_rms_scatt', 'Oi_chi2',\n",
    "                'Oz_Nobs', 'Oz_mMed', 'Oz_mMean', 'Oz_mErr', 'Oz_rms_scatt', 'Oz_chi2']\n",
    "\n",
    "# USING DASK DATAFRAME\n",
    "df_oSSC = dd.read_csv(oSSC,delim_whitespace=True,comment='#',names=Ocolnames)\n",
    "old_df = df_oSSC.compute()\n",
    "# old_df.head()\n",
    "orows,ocols = old_df.shape\n",
    "print('Old df, as read: num rows, cols: ',orows,ocols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Old df, as read: num rows %d, cols %d\\n' % (orows,ocols));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SET UP THE DATAFRAMES PRIOR TO MATCHING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old df, prematch: num rows, cols:  1006849 37\n",
      "New df, prematch: num rows, cols:  929407 37\n"
     ]
    }
   ],
   "source": [
    "new_prematch_df = new_df4\n",
    "old_prematch_df = old_df\n",
    "\n",
    "prematch_orows,prematch_ocols = old_prematch_df.shape\n",
    "print('Old df, prematch: num rows, cols: ',prematch_orows,prematch_ocols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Old df, prematch: num rows %d, cols %d\\n' % (prematch_orows,prematch_ocols));\n",
    "\n",
    "prematch_nrows,prematch_ncols = new_prematch_df.shape\n",
    "print('New df, prematch: num rows, cols: ',prematch_nrows,prematch_ncols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, prematch: num rows %d, cols %d\\n' % (prematch_nrows,prematch_ncols));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SAVE PREMATCH NEW DF TO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prematch csv:  NEW_stripe82calibStars_prematch.csv\n",
      "CPU times: user 1min 5s, sys: 879 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "paths = nSSC_prematch  \n",
    "prematch_csv = new_prematch_df.to_csv(paths,na_rep=-99.99,index=False)\n",
    "\n",
    "print('Prematch csv: ',nSSC_prematch)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Prematch csv %s\\n' % nSSC_prematch);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MATCH CLEANED UP NEW CAT WITH THE OLD CAT**\n",
    "\n",
    "TRY PYSPHEREMATCH, PERHAPS WITH DASK.DELAYED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num matched new - old: 929317\n",
      "CPU times: user 46 s, sys: 205 ms, total: 46.2 s\n",
      "Wall time: 46.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "idxs1, idxs2, ds = pyspherematch.spherematch(\n",
    "        np.array(new_prematch_df['Nra']),\n",
    "        np.array(new_prematch_df['Ndec']),\n",
    "        np.array(old_prematch_df['Ora']),\n",
    "        np.array(old_prematch_df['Odec']),\n",
    "        tol=tol_deg)\n",
    "\n",
    "nmatch = len(idxs1)\n",
    "print('Num matched new - old:', nmatch)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Num matched new - old: %d\\n' % nmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GET MATCHED SUBSETS OF THE DATAFRAMES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old df, as matched: num rows, cols:  929317 37\n",
      "New df, as matched: num rows, cols:  929317 37\n"
     ]
    }
   ],
   "source": [
    "new_matched_df = new_prematch_df.iloc[idxs1]\n",
    "old_matched_df = old_prematch_df.iloc[idxs2]\n",
    "\n",
    "matched_orows,matched_ocols = old_matched_df.shape\n",
    "print('Old df, as matched: num rows, cols: ',matched_orows,matched_ocols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Old df, as matched: num rows %d, cols %d\\n' % (matched_orows,matched_ocols));\n",
    "\n",
    "matched_nrows,matched_ncols = new_matched_df.shape\n",
    "print('New df, as matched: num rows, cols: ',matched_nrows,matched_ncols)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New df, as matched: num rows %d, cols %d\\n' % (matched_nrows,matched_ncols));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **WRITE OUT THE MATCHED DF TO CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Matched csv:  NEW_stripe82calibStars_matched.csv\n",
      "Old Matched csv:  stripe82calibStars_matched.csv\n",
      "CPU times: user 2min 8s, sys: 1.6 s, total: 2min 9s\n",
      "Wall time: 2min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "paths = nSSC_matched  \n",
    "nmatched_csv = new_matched_df.to_csv(paths,na_rep=-99.99,index=False)\n",
    "\n",
    "print('New Matched csv: ',nSSC_matched)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('New Matched csv %s\\n' % nSSC_matched);\n",
    "\n",
    "paths = oSSC_matched  \n",
    "omatched_csv = old_matched_df.to_csv(paths,na_rep=-99.99,index=False)\n",
    "\n",
    "print('Old Matched csv: ',oSSC_matched)\n",
    "outlog.write('*************************\\n')\n",
    "outlog.write('Old Matched csv %s\\n' % oSSC_matched);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLOSE THE LOG FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLOSE THE LOG FILE\n",
    "outlog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
